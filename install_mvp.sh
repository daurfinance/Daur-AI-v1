#!/bin/bash
# Daur AI MVP Installation Script
# Installs all dependencies and sets up local LLM

set -e

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                                                           â•‘"
echo "â•‘         ğŸ¤– Daur AI MVP Installation ğŸ¤–                    â•‘"
echo "â•‘                                                           â•‘"
echo "â•‘              100% Local LLM Solution                      â•‘"
echo "â•‘                                                           â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Detect OS
OS="$(uname -s)"
echo "ğŸ–¥ï¸  Detected OS: $OS"
echo ""

# Check Python
echo "ğŸ Checking Python..."
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python 3 not found. Please install Python 3.8 or higher."
    exit 1
fi

PYTHON_VERSION=$(python3 --version | cut -d' ' -f2)
echo "âœ… Python $PYTHON_VERSION found"
echo ""

# Install Python dependencies
echo "ğŸ“¦ Installing Python dependencies..."
pip3 install -r requirements-mvp.txt
echo "âœ… Python dependencies installed"
echo ""

# Install Tesseract OCR
echo "ğŸ” Installing Tesseract OCR..."
if [ "$OS" = "Darwin" ]; then
    # macOS
    if command -v brew &> /dev/null; then
        brew install tesseract
        echo "âœ… Tesseract installed via Homebrew"
    else
        echo "âš ï¸  Homebrew not found. Please install Tesseract manually:"
        echo "   https://github.com/tesseract-ocr/tesseract"
    fi
elif [ "$OS" = "Linux" ]; then
    # Linux
    if command -v apt-get &> /dev/null; then
        sudo apt-get update
        sudo apt-get install -y tesseract-ocr
        echo "âœ… Tesseract installed via apt"
    elif command -v yum &> /dev/null; then
        sudo yum install -y tesseract
        echo "âœ… Tesseract installed via yum"
    else
        echo "âš ï¸  Package manager not found. Please install Tesseract manually."
    fi
else
    echo "âš ï¸  Please install Tesseract manually for your OS"
fi
echo ""

# Install Ollama
echo "ğŸ¤– Installing Ollama..."
if ! command -v ollama &> /dev/null; then
    if [ "$OS" = "Darwin" ]; then
        # macOS
        if command -v brew &> /dev/null; then
            brew install ollama
            echo "âœ… Ollama installed via Homebrew"
        else
            echo "âš ï¸  Homebrew not found. Installing Ollama manually..."
            curl -fsSL https://ollama.com/install.sh | sh
        fi
    elif [ "$OS" = "Linux" ]; then
        # Linux
        curl -fsSL https://ollama.com/install.sh | sh
        echo "âœ… Ollama installed"
    else
        echo "âš ï¸  Please install Ollama manually from https://ollama.com/download"
    fi
else
    echo "âœ… Ollama already installed"
fi
echo ""

# Start Ollama server
echo "ğŸš€ Starting Ollama server..."
if [ "$OS" = "Darwin" ]; then
    # macOS - start as background service
    brew services start ollama 2>/dev/null || ollama serve &
elif [ "$OS" = "Linux" ]; then
    # Linux - start in background
    nohup ollama serve > /dev/null 2>&1 &
fi

# Wait for Ollama to start
echo "â³ Waiting for Ollama server to start..."
sleep 5

# Check if Ollama is running
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âœ… Ollama server is running"
else
    echo "âš ï¸  Ollama server may not be running. Please start it manually:"
    echo "   ollama serve"
fi
echo ""

# Download models
echo "â¬‡ï¸  Downloading AI models (this may take 5-10 minutes)..."
echo ""

echo "ğŸ“¥ Downloading Llama 3.2 3B (main model)..."
ollama pull llama3.2:3b
echo "âœ… Llama 3.2 3B downloaded"
echo ""

echo "ğŸ“¥ Downloading LLaVA (vision model)..."
ollama pull llava
echo "âœ… LLaVA downloaded"
echo ""

echo "ğŸ“¥ Downloading CodeLlama 7B (coding model)..."
ollama pull codellama:7b
echo "âœ… CodeLlama downloaded"
echo ""

# Verify installation
echo "ğŸ” Verifying installation..."
echo ""

# Check models
MODELS=$(ollama list | grep -E 'llama3.2:3b|llava|codellama:7b' | wc -l)
if [ "$MODELS" -ge 3 ]; then
    echo "âœ… All models installed successfully"
else
    echo "âš ï¸  Some models may be missing. Run 'ollama list' to check."
fi
echo ""

# Installation complete
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                                                           â•‘"
echo "â•‘              âœ… Installation Complete! âœ…                 â•‘"
echo "â•‘                                                           â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ‰ Daur AI MVP is ready to use!"
echo ""
echo "To start the agent:"
echo "  python3 mvp_chat.py"
echo ""
echo "Or run a task directly:"
echo "  python3 -c 'from src.mvp import get_mvp_agent; import asyncio; asyncio.run(get_mvp_agent().execute_task(\"open Safari\"))'"
echo ""
echo "For help:"
echo "  python3 mvp_chat.py"
echo "  Then type: /help"
echo ""

